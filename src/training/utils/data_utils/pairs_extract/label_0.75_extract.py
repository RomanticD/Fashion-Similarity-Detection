import json
from pathlib import Path
import argparse
import random
from collections import defaultdict
from PIL import Image


# ======================
# å¯è°ƒæ•´å‚æ•°ï¼ˆé›†ä¸­åœ¨å¼€å¤´ï¼Œæ”¯æŒå‘½ä»¤è¡Œè¦†ç›–ï¼‰
# ======================
INPUT_DIR = "/Users/sunyuliang/Desktop/AppBuilder/Python/deepfashion_train"  # åŸå§‹æ•°æ®ç›®å½•
IMAGE_DIR_NAME = "image"         # å›¾ç‰‡æ–‡ä»¶å¤¹å
ANNO_DIR_NAME = "annos"          # DeepFashion2åŸå§‹annosæ–‡ä»¶å¤¹
PAIRS_OUTPUT_DIR = "/Users/sunyuliang/Desktop/AppBuilder/Python/dinov2_train/Label_0.75"  # è¾“å‡ºç›®å½•
RANDOM_SEED = 42                 # éšæœºç§å­
MIN_STYLE = 1                    # æœ‰æ•ˆstyleé˜ˆå€¼ï¼ˆstyle>0ï¼‰
CROP_PADDING = 10                # è£å‰ªæ—¶çš„è¾¹ç•Œå¡«å……ï¼ˆåƒç´ ï¼‰
MAX_ITEMS_PER_PAIR_ID = 50        # æ¯ä¸ªpair_idç»„å†…çš„æœ€å¤§å…ƒç´ æ•°é‡
MAX_PAIR_ID_OCCURRENCE = 5       # åŒä¸€ä¸ªpair_idçš„æœ€å¤§å‡ºç°æ¬¡æ•°


def parse_arguments():
    parser = argparse.ArgumentParser(description='æå–label=0.75çš„åŒç±»åˆ«ä¸åŒæ¬¾å¼å¯¹ï¼ˆä¸åŒpair_id+åŒcategory_id+style>0ï¼‰')
    parser.add_argument('--batch_start', type=int, default=1,
                        help='æ‰¹æ¬¡èµ·å§‹pair_idï¼ˆDeepFashion2çš„pair_idèŒƒå›´ï¼‰')
    parser.add_argument('--batch_end', type=int, default=100000,
                        help='æ‰¹æ¬¡ç»“æŸpair_idï¼ˆDeepFashion2çš„pair_idèŒƒå›´ï¼‰')
    parser.add_argument('--pairs_to_extract', type=int, default=1000,
                        help='ç›®æ ‡æå–å¯¹æ•°')
    return parser.parse_args()


def image_id_from_filename(filename):
    """ä»æ–‡ä»¶åæå–6ä½æ•°å­—ID"""
    return int(filename.stem[:6])  # æˆªå–å‰6ä½


def load_valid_items(args):
    """åŠ è½½æœ‰æ•ˆitemå¹¶æŒ‰category_idåˆ†ç»„ï¼ˆè¿‡æ»¤style>0ï¼‰"""
    input_path = Path(INPUT_DIR)
    image_dir = input_path / IMAGE_DIR_NAME
    anno_dir = input_path / ANNO_DIR_NAME

    valid_items = defaultdict(list)  # key: category_id,
    # value: list of (img_id, pair_id, item, img_path, anno_path, original_pair_id)

    for anno_file in anno_dir.glob("*.json"):
        img_id = image_id_from_filename(anno_file)
        if not (args.batch_start <= img_id <= args.batch_end):
            continue

        img_path = image_dir / f"{img_id:06d}.jpg"
        if not img_path.exists():
            continue

        with open(anno_file, 'r') as f:
            data = json.load(f)
        deepfashion_pair_id = data.get("pair_id")  # åŸå§‹pair_id
        if not deepfashion_pair_id:
            continue

        for item_key in data:
            if not item_key.startswith("item"):
                continue
            item_data = data[item_key]
            if item_data.get("style", 0) < MIN_STYLE or not item_data.get("bounding_box"):
                continue
            category_id = item_data["category_id"]
            valid_items[category_id].append((
                img_id,           # å›¾ç‰‡ID
                deepfashion_pair_id,  # åŸå§‹pair_id
                item_data,        # ç‰©å“ä¿¡æ¯
                str(img_path),    # å›¾ç‰‡è·¯å¾„
                str(anno_file),   # æ ‡æ³¨è·¯å¾„
                deepfashion_pair_id  # æ–°å¢åŸå§‹ pair_id
            ))

    return valid_items


def generate_similar_pairs(valid_items, pairs_to_extract):
    """ç”Ÿæˆä¸åŒpair_idã€åŒcategory_idã€style>0çš„ç›¸ä¼¼æ ·æœ¬å¯¹"""
    similar_pairs = []
    random.seed(RANDOM_SEED)
    pair_id_usage_count = defaultdict(int)  # è®°å½•æ¯ä¸ªpair_idçš„ä½¿ç”¨æ¬¡æ•°
    category_usage_count = defaultdict(int)  # è®°å½•æ¯ä¸ªç±»åˆ«çš„ä½¿ç”¨æ¬¡æ•°
    total_categories = len(valid_items)

    # è®¡ç®—æ¯ä¸ªç±»åˆ«å¤§è‡´åº”åˆ†é…çš„é…å¯¹æ•°é‡
    base_pairs_per_category = pairs_to_extract // total_categories
    remaining_pairs = pairs_to_extract % total_categories

    category_list = list(valid_items.keys())
    random.shuffle(category_list)

    for category_id in category_list:
        items_in_category = valid_items[category_id]
        # æŒ‰pair_idåˆ†ç»„ï¼Œé¿å…åŒpair_idå†…é…å¯¹
        pair_groups = defaultdict(list)
        for item in items_in_category:
            if len(pair_groups[item[1]]) < MAX_ITEMS_PER_PAIR_ID:
                pair_groups[item[1]].append(item)  # æŒ‰pair_idåˆ†ç»„ï¼škey=pair_id, value=è¯¥pair_idä¸‹çš„æ‰€æœ‰item

        # æå–æ‰€æœ‰ä¸åŒpair_idçš„ç»„åˆ
        pair_ids = list(pair_groups.keys())
        num_pairs_for_this_category = base_pairs_per_category
        if remaining_pairs > 0:
            num_pairs_for_this_category += 1
            remaining_pairs -= 1

        while num_pairs_for_this_category > 0 and len(pair_ids) >= 2:
            pair_id_i = random.choice(pair_ids)
            pair_ids.remove(pair_id_i)
            pair_id_j = random.choice(pair_ids)

            if pair_id_usage_count[pair_id_i] >= MAX_PAIR_ID_OCCURRENCE or pair_id_usage_count[pair_id_j] >= MAX_PAIR_ID_OCCURRENCE:
                continue

            items_i = pair_groups[pair_id_i]
            items_j = pair_groups[pair_id_j]

            item_i = random.choice(items_i)
            item_j = random.choice(items_j)

            similar_pairs.append((item_i, item_j))
            pair_id_usage_count[pair_id_i] += 1
            pair_id_usage_count[pair_id_j] += 1
            category_usage_count[category_id] += 1
            num_pairs_for_this_category -= 1

            if len(similar_pairs) >= pairs_to_extract:
                break

        if len(similar_pairs) >= pairs_to_extract:
            break

    random.shuffle(similar_pairs)
    return similar_pairs[:pairs_to_extract]


def crop_clothing_image(img_path, bbox, padding=CROP_PADDING):
    """æ ¹æ®è¾¹ç•Œæ¡†è£å‰ªè¡£ç‰©åŒºåŸŸ"""
    try:
        img = Image.open(img_path)
        x1, y1, x2, y2 = bbox
        x1 = max(0, x1 - padding)
        y1 = max(0, y1 - padding)
        x2 = min(img.width, x2 + padding)
        y2 = min(img.height, y2 + padding)
        return img.crop((x1, y1, x2, y2))
    except Exception as e:
        print(f"è£å‰ªå¤±è´¥ {img_path} (è¾¹ç•Œæ¡†{bbox}): {str(e)}")
        return None


def save_pair_metadata(pair_dir, current_pair_num, img1_info, img2_info):
    """ä¿å­˜ä¼˜åŒ–åçš„metadataç»“æ„"""
    # è§£æåŸå§‹ä¿¡æ¯
    img1_id, pair1_id, item1, img1_path, anno1_path, original_pair_id1 = img1_info
    img2_id, pair2_id, item2, img2_path, anno2_path, original_pair_id2 = img2_info

    # ç”Ÿæˆæ–°çš„pair_idå’Œimage_id
    new_pair_id = f"pair_{current_pair_num:04d}"
    image1_id = f"{new_pair_id}_1"
    image2_id = f"{new_pair_id}_2"

    metadata = {
        "pair_id": new_pair_id,
        "similarity": 0.75,
        "image1": {
            "image_id": image1_id,
            "original_image_id": img1_id,     # DeepFashion2åŸå§‹å›¾ç‰‡ID
            "original_pair_id": original_pair_id1,  # æ–°å¢åŸå§‹ pair_id
            "category_id": item1["category_id"],
            "style": item1["style"],
            "bounding_box": item1["bounding_box"],
            "image_path": str(pair_dir / "image_01.jpg"),
            "original_anno_path": anno1_path
        },
        "image2": {
            "image_id": image2_id,
            "original_image_id": img2_id,
            "original_pair_id": original_pair_id2,  # æ–°å¢åŸå§‹ pair_id
            "category_id": item2["category_id"],
            "style": item2["style"],
            "bounding_box": item2["bounding_box"],
            "image_path": str(pair_dir / "image_02.jpg"),
            "original_anno_path": anno2_path
        }
    }
    with open(pair_dir / "metadata.json", "w") as f:
        json.dump(metadata, f, indent=4)


def save_pairs_to_output(pairs, output_dir):
    """ä¿å­˜é…å¯¹å›¾ç‰‡å’Œå…ƒæ•°æ®"""
    output_path = Path(output_dir)
    output_path.mkdir(parents=True, exist_ok=True)
    current_pair_num = 1

    for img1_info, img2_info in pairs:
        # è§£æä¿¡æ¯
        img1_id, pair1_id, item1, img1_path, anno1_path, original_pair_id1 = img1_info
        img2_id, pair2_id, item2, img2_path, anno2_path, original_pair_id2 = img2_info

        # è£å‰ªå›¾ç‰‡
        img1_cropped = crop_clothing_image(img1_path, item1["bounding_box"])
        img2_cropped = crop_clothing_image(img2_path, item2["bounding_box"])
        if not img1_cropped or not img2_cropped:
            continue

        # åˆ›å»ºå¯¹ç›®å½•
        pair_dir = output_path / f"pair_{current_pair_num:04d}"
        pair_dir.mkdir(exist_ok=True)

        # ä¿å­˜å›¾ç‰‡
        img1_cropped.save(pair_dir / "image_01.jpg")
        img2_cropped.save(pair_dir / "image_02.jpg")

        # ä¿å­˜å…ƒæ•°æ®
        save_pair_metadata(pair_dir, current_pair_num, img1_info, img2_info)

        print(f"âœ… ä¿å­˜ç¬¬{current_pair_num:04d}å¯¹: {pair_dir}")
        current_pair_num += 1


if __name__ == "__main__":
    args = parse_arguments()
    random.seed(RANDOM_SEED)

    # 1. åŠ è½½æœ‰æ•ˆitemï¼ˆæŒ‰category_idåˆ†ç»„ï¼Œè¿‡æ»¤style>0ï¼‰
    print(f"\n=== åŠ è½½category_idæœ‰æ•ˆçš„itemï¼ˆstyle>0ï¼‰===")
    valid_items = load_valid_items(args)
    if not valid_items:
        print("âŒ æœªæ‰¾åˆ°æœ‰æ•ˆitemï¼ˆæ£€æŸ¥styleå’Œcategory_idï¼‰")
        exit(1)

    # 2. ç”Ÿæˆè·¨pair_idçš„åŒcategory_idé…å¯¹
    print(f"\n=== ç”Ÿæˆ{args.pairs_to_extract}å¯¹label=0.75çš„æ ·æœ¬ï¼ˆä¸åŒpair_id+åŒcategory_idï¼‰===")
    similar_pairs = generate_similar_pairs(valid_items, args.pairs_to_extract)
    if not similar_pairs:
        print(f"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„é…å¯¹ï¼ˆæ£€æŸ¥category_idåˆ†å¸ƒï¼‰")
        exit(1)

    # 3. ä¿å­˜é…å¯¹
    print(f"\n=== å¼€å§‹ä¿å­˜é…å¯¹åˆ° {PAIRS_OUTPUT_DIR} ===")
    save_pairs_to_output(similar_pairs, PAIRS_OUTPUT_DIR)
    print(f"\nğŸ‰ å®Œæˆï¼å…±ä¿å­˜{len(similar_pairs)}å¯¹label=0.75çš„ç›¸ä¼¼æ ·æœ¬")
