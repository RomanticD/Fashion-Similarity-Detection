#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""
æµ‹è¯•è„šæœ¬: è¿›è¡Œå›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹æµ‹è¯•
ç”¨æ³•: python test_image_similarity.py
"""

import argparse
import sys
from pathlib import Path
from PIL import Image
import numpy as np
import base64
import json
import pickle
import shutil
import io

# å¯¼å…¥ ImageSimilarity ç±»
from src.core.image_similarity import ImageSimilarity
from src.core.image_similarity_vit import ImageSimilarityViT

from src.core.groundingdino_handler import ClothingDetector
from src.repo.split_images_repo import select_image_data_by_id, select_multiple_image_data_by_ids


def parse_arguments():
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(description='æµ‹è¯•å›¾ç‰‡ç›¸ä¼¼åº¦æ£€æµ‹')
    return parser.parse_args()


def find_project_root():
    """æŸ¥æ‰¾é¡¹ç›®æ ¹ç›®å½•"""
    current_dir = Path.cwd()

    # å°è¯•å‘ä¸ŠæŸ¥æ‰¾åŒ…å«README.mdçš„ç›®å½•
    while current_dir != current_dir.parent:
        if (current_dir / 'README.md').exists():
            return current_dir
        current_dir = current_dir.parent

    # å¦‚æœæ‰¾ä¸åˆ°ï¼Œåˆ™ä½¿ç”¨å½“å‰ç›®å½•
    return Path.cwd()


def load_images(image_dir):
    """åŠ è½½æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰å›¾ç‰‡"""
    image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']
    image_files = []
    for ext in image_extensions:
        image_files.extend(list(image_dir.rglob(f'*{ext}')))  # ä½¿ç”¨ rglob é€’å½’æŸ¥æ‰¾
        image_files.extend(list(image_dir.rglob(f'*{ext.upper()}')))  # æ£€æŸ¥å¤§å†™æ‰©å±•å

    if not image_files:
        print(f"âŒ é”™è¯¯: å›¾ç‰‡ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶: {image_dir}")
        sys.exit(1)

    print(f"âœ… æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
    return image_files


def image_to_base64(image_path):
    """å°†å›¾ç‰‡æ–‡ä»¶è½¬æ¢ä¸ºBase64ç¼–ç å­—ç¬¦ä¸²"""
    try:
        with open(image_path, "rb") as image_file:
            encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
        return encoded_string
    except Exception as e:
        print(f"âŒ é”™è¯¯: è¯»å–å›¾ç‰‡æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        sys.exit(1)


def load_vector_index(root_dir):
    """åŠ è½½å‘é‡ç´¢å¼•"""
    index_file = root_dir / 'vector_nn_index.pkl'
    id_map_file = root_dir / 'vector_id_map.json'
    try:
        with open(index_file, 'rb') as f:
            data = pickle.load(f)
            index = data['index']
            vectors = data['vectors']
        with open(id_map_file, 'r') as f:
            id_map = json.load(f)
        return index, id_map
    except FileNotFoundError:
        print("âŒ é”™è¯¯: å‘é‡ç´¢å¼•æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè¯·å…ˆæ„å»ºå‘é‡ç´¢å¼•ã€‚")
        sys.exit(1)


def get_similar_images(image_path, index, id_map, similarity, num=5):
    """è·å–ç›¸ä¼¼å›¾ç‰‡"""
    # è¯»å–å›¾ç‰‡
    image = Image.open(image_path).convert('RGB')
    image_np = np.array(image)

    # æ£€æµ‹æœè£…ç‰©å“
    clothing_detector = ClothingDetector()
    segmented_images = clothing_detector.detect_clothes(image_np)

    if not segmented_images:
        print("æœªåœ¨å›¾åƒä¸­æ£€æµ‹åˆ°æœè£…ç‰©å“ï¼Œä½¿ç”¨æ•´å¼ å›¾åƒè¿›è¡Œç›¸ä¼¼åº¦æ£€æµ‹ã€‚")
        segmented_images = [image_np.copy()]

    # æå–ç‰¹å¾å‘é‡
    feature_vectors = []
    for img in segmented_images:
        feature = similarity.extract_feature(img)
        feature_vectors.append(feature)

    # è®¡ç®—å¹³å‡ç‰¹å¾å‘é‡
    avg_feature_vector = np.mean(feature_vectors, axis=0)

    # æœç´¢ç›¸ä¼¼å›¾ç‰‡
    distances, indices = index.kneighbors([avg_feature_vector], n_neighbors=num)

    similar_images = []
    for idx, dist in zip(indices[0], distances[0]):
        image_id = id_map[idx]
        similarity_score = 1 - dist  # æ ¹æ®è·ç¦»è®¡ç®—ç›¸ä¼¼åº¦
        similar_images.append({
            "id": image_id,
            "similarity": similarity_score,
            "processed_image_base64": ""  # è¿™é‡Œæš‚æ—¶ä¸æä¾›å¤„ç†åçš„å›¾ç‰‡ï¼Œå¯æ ¹æ®éœ€æ±‚æ·»åŠ 
        })

    return similar_images


def save_similar_images_from_db(image_sub_dir, similar_images):
    """ä»æ•°æ®åº“è·å–å›¾ç‰‡æ•°æ®å¹¶ä¿å­˜åˆ°æŒ‡å®šæ–‡ä»¶å¤¹"""
    # æå–æ‰€æœ‰ç›¸ä¼¼å›¾ç‰‡çš„ID
    ids = [item['id'] for item in similar_images]
    print(f"ğŸ” å°è¯•æ‰¹é‡æŸ¥è¯¢çš„å›¾ç‰‡ID: {ids}")

    # ä»æ•°æ®åº“ä¸­è·å–å›¾ç‰‡æ•°æ®
    image_data_dict = select_multiple_image_data_by_ids(ids)
    print(f"ä»æ•°æ®åº“è·å–åˆ°çš„å›¾ç‰‡æ•°æ®æ•°é‡: {len(image_data_dict)}")

    for idx, item in enumerate(similar_images, start=1):
        image_id = item['id']
        # æŸ¥æ‰¾å¯¹åº”çš„å›¾ç‰‡æ•°æ®
        image_data = image_data_dict.get(image_id)
        if image_data:
            binary_image_data = image_data['splitted_image_data']
            try:
                # å°†äºŒè¿›åˆ¶æ•°æ®è½¬æ¢ä¸º PIL å›¾åƒ
                img = Image.open(io.BytesIO(binary_image_data))
                new_image_name = f"similar_{idx:02d}.png"
                new_image_path = image_sub_dir / new_image_name
                img.save(new_image_path)
                print(f"âœ… ç›¸ä¼¼å›¾ç‰‡ {new_image_path} å·²ä¿å­˜")
            except Exception as e:
                print(f"âŒ ä¿å­˜å›¾ç‰‡æ—¶å‡ºé”™: {e}")
        else:
            print(f"âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼Œå›¾ç‰‡ID: {image_id}")


def save_similar_images(image_sub_dir, similar_images):
    """ä¿å­˜ç›¸ä¼¼å›¾ç‰‡å¹¶ç”Ÿæˆæ–‡æœ¬æ–‡ä»¶"""
    # å¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œå…ˆæ¸…ç©º
    if image_sub_dir.exists():
        for item in image_sub_dir.iterdir():
            if item.is_file():
                item.unlink()
            elif item.is_dir():
                shutil.rmtree(item)
    image_sub_dir.mkdir(parents=True, exist_ok=True)

    details = []
    for idx, item in enumerate(similar_images):
        try:
            details.append(f"åç§°: {item['id']}, ç›¸ä¼¼åº¦: {item['similarity']:.4f}")
        except Exception as e:
            print(f"âŒ å¤„ç†ç›¸ä¼¼å›¾ç‰‡ä¿¡æ¯æ—¶å‡ºé”™: {e}")

    # ä¿å­˜ç»†èŠ‚ä¿¡æ¯åˆ°æ–‡æœ¬æ–‡ä»¶
    details_file = image_sub_dir / "similarity_details.txt"
    with open(details_file, 'w') as f:
        for detail in details:
            f.write(detail + '\n')
    print(f"âœ… ç›¸ä¼¼å›¾ç‰‡ç»†èŠ‚ä¿¡æ¯å·²ä¿å­˜åˆ° {details_file}")


def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‚æ•°
    args = parse_arguments()

    # æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•
    root_dir = find_project_root()
    print(f"ğŸ“ é¡¹ç›®æ ¹ç›®å½•: {root_dir}")

    # ç¡®è®¤å›¾ç‰‡ç›®å½•è·¯å¾„
    image_dir = root_dir / "assets" / "test_image_similarity"
    if not image_dir.exists() or not image_dir.is_dir():
        print(f"âŒ é”™è¯¯: å›¾ç‰‡ç›®å½•ä¸å­˜åœ¨: {image_dir}")
        sys.exit(1)

    # åŠ è½½å›¾ç‰‡
    image_files = load_images(image_dir)

    # åˆ›å»ºdata/test_similarityç›®å½•
    data_dir = root_dir / "data"
    data_dir.mkdir(parents=True, exist_ok=True)
    test_dir = data_dir / "test_similarity"
    test_dir.mkdir(parents=True, exist_ok=True)

    # åˆå§‹åŒ– ImageSimilarity ç±»
    # similarity = ImageSimilarity()
    similarity = ImageSimilarityViT()

    # åŠ è½½å‘é‡ç´¢å¼•
    index, id_map = load_vector_index(root_dir)

    # æ‰¹é‡å¤„ç†å›¾ç‰‡
    for image_path in image_files:
        image_name = Path(image_path).stem
        image_sub_dir = test_dir / f"test_{image_name}"

        # è·å–ç›¸ä¼¼å›¾ç‰‡
        similar_images = get_similar_images(image_path, index, id_map, similarity)
        print(f"ğŸ” ä¸ºå›¾ç‰‡ {image_path} æ‰¾åˆ°çš„ç›¸ä¼¼å›¾ç‰‡æ•°é‡: {len(similar_images)}")

        # ä¿å­˜ç›¸ä¼¼å›¾ç‰‡å¹¶ç”Ÿæˆæ–‡æœ¬æ–‡ä»¶
        save_similar_images(image_sub_dir, similar_images)

        # ä»æ•°æ®åº“ä¸­è·å–å¹¶ä¿å­˜ç›¸ä¼¼å›¾ç‰‡
        save_similar_images_from_db(image_sub_dir, similar_images)


if __name__ == "__main__":
    main()
